{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from ssk import ssk\n",
    "from score import get_scores_df\n",
    "import pandas as pd\n",
    "from stocksymbol import StockSymbol\n",
    "from returns import get_yearly_normalized_price, get_monthly_adjusted_price\n",
    "from pairs import get_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = StockSymbol(ssk)\n",
    "\n",
    "# Get tickers of companies listed in NASDAQ\n",
    "symbol_list = ssm.get_symbol_list(market=\"US\")\n",
    "nasdaq_list = [x['symbol'] for x in symbol_list if x['exchange'] == 'NASDAQ']\n",
    "\n",
    "# Randomly sample 100 of them\n",
    "nasdaq_list = list(pd.Series(nasdaq_list).sample(700, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjusted prices and scores\n",
    "\n",
    "yearly_normalized_price = get_yearly_normalized_price(ticker_list=nasdaq_list, start_year = 2009)\n",
    "yearly_normalized_price.to_csv(\"csv/normalized price trend.csv\", index=False)\n",
    "\n",
    "fundamental_scores = get_scores_df(ticker_list=nasdaq_list)\n",
    "\n",
    "for variable in fundamental_scores:\n",
    "    fundamental_scores[variable].to_csv(\"csv/normalized {} trend.csv\".format(variable), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "def get_pair_distance(df, start_year_month=None, end_year_month=None):\n",
    "    '''\n",
    "    Receives a dataframe with index being the date (could be years) and \n",
    "    columns are the stocks then calculates the spread using sum of squared distance\n",
    "    '''\n",
    "\n",
    "    if(start_year_month != None):\n",
    "        df = df[df.index >= start_year_month]\n",
    "    if(end_year_month != None):\n",
    "        df = df[df.index < end_year_month]\n",
    "\n",
    "    df = df.dropna(axis=1)\n",
    "\n",
    "    # df_corr = {}\n",
    "\n",
    "    # # calculate the sum of squared difference for each column\n",
    "    # for stock_1 in df:\n",
    "    #     df_corr[stock_1] = {}\n",
    "    #     for stock_2 in df:\n",
    "    #         if stock_1 != stock_2:\n",
    "    #             ssd = ((df[stock_1] - df[stock_2])**2).sum()\n",
    "    #             df_corr[stock_1][stock_2] = ssd\n",
    "\n",
    "    df_corr = df.corr()\n",
    "\n",
    "    pairs = {}\n",
    "    for col in df_corr:\n",
    "        for row in df_corr.index:\n",
    "\n",
    "            key = '_'.join([val for val in sorted([col, row])])\n",
    "\n",
    "            # If we already have a pair (a, b), we don't want another\n",
    "            # pair (b, a). We also don't want a pair of an asset and itself\n",
    "            if(row != col and key not in pairs):\n",
    "                pairs[key] = df_corr[row][col]\n",
    "\n",
    "    return pd.Series(pairs).sort_values(ascending=False)\n",
    "\n",
    "def get_distance(df1, df2_list = [], start_year_month=None, end_year_month=None):\n",
    "    # because we don't want to alter the original df1 sent in this function\n",
    "    df = copy.deepcopy(df1)\n",
    "    \n",
    "    # because if column has all values as NaN, multiplying by others will result\n",
    "    # in all of them having NaN\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # We expect df1 and df2 to have the same column names with the content\n",
    "    # being for different variables. For instance, one df will have information\n",
    "    # about normalized ebtda-margin, while another will have information about\n",
    "    # normalized cost of goods sold\n",
    "    for df2 in df2_list:\n",
    "        df2 = df2.dropna(axis=1, how='all')\n",
    "        for column in df1:\n",
    "            try:\n",
    "                df[column] = df[column] * df2[column]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return get_pair_distance(df, start_year_month, end_year_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "def get_pair_distance(df, start_year_month=None, end_year_month=None):\n",
    "    '''\n",
    "    Receives a dataframe with index being the date (could be years) and \n",
    "    columns are the stocks then calculates the spread using sum of squared distance\n",
    "    '''\n",
    "\n",
    "    if(start_year_month != None):\n",
    "        df = df[df.index >= start_year_month]\n",
    "    if(end_year_month != None):\n",
    "        df = df[df.index < end_year_month]\n",
    "\n",
    "    df = df.dropna(axis=1)\n",
    "\n",
    "    # df_corr = {}\n",
    "\n",
    "    # # calculate the sum of squared difference for each column\n",
    "    # for stock_1 in df:\n",
    "    #     df_corr[stock_1] = {}\n",
    "    #     for stock_2 in df:\n",
    "    #         if stock_1 != stock_2:\n",
    "    #             ssd = ((df[stock_1] - df[stock_2])**2).sum()\n",
    "    #             df_corr[stock_1][stock_2] = ssd\n",
    "\n",
    "    df_corr = df.corr()\n",
    "\n",
    "    pairs = {}\n",
    "    for col in df_corr:\n",
    "        for row in df_corr.index:\n",
    "\n",
    "            key = '_'.join([val for val in sorted([col, row])])\n",
    "\n",
    "            # If we already have a pair (a, b), we don't want another\n",
    "            # pair (b, a). We also don't want a pair of an asset and itself\n",
    "            if(row != col and key not in pairs):\n",
    "                pairs[key] = df_corr[row][col]\n",
    "\n",
    "    return pd.Series(pairs).sort_values(ascending=False)\n",
    "\n",
    "def get_distance(df1, df2_list = [], start_year_month=None, end_year_month=None):\n",
    "    # because we don't want to alter the original df1 sent in this function\n",
    "    df = copy.deepcopy(df1)\n",
    "    \n",
    "    # because if column has all values as NaN, multiplying by others will result\n",
    "    # in all of them having NaN\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # We expect df1 and df2 to have the same column names with the content\n",
    "    # being for different variables. For instance, one df will have information\n",
    "    # about normalized ebtda-margin, while another will have information about\n",
    "    # normalized cost of goods sold\n",
    "    for df2 in df2_list:\n",
    "        df2 = df2.dropna(axis=1, how='all')\n",
    "        for column in df1:\n",
    "            try:\n",
    "                df[column] = df[column] * df2[column]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return get_pair_distance(df, start_year_month, end_year_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ebtda-margin</th>\n",
       "      <th>gross-profit-margin</th>\n",
       "      <th>cogs-margin</th>\n",
       "      <th>eps-earnings-per-share-diluted</th>\n",
       "      <th>all-fundamental-variables</th>\n",
       "      <th>price-pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AACG_GURE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993198</td>\n",
       "      <td>0.993199</td>\n",
       "      <td>0.586029</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEBO_UBOH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992070</td>\n",
       "      <td>0.992069</td>\n",
       "      <td>0.643873</td>\n",
       "      <td>0.643874</td>\n",
       "      <td>0.901189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVBF_FCCO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990282</td>\n",
       "      <td>0.990282</td>\n",
       "      <td>-0.557460</td>\n",
       "      <td>0.557460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FBIZ_UBOH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987049</td>\n",
       "      <td>0.987048</td>\n",
       "      <td>0.769316</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.768724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUB_HAFC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986588</td>\n",
       "      <td>0.986588</td>\n",
       "      <td>-0.661878</td>\n",
       "      <td>0.661878</td>\n",
       "      <td>0.795130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ebtda-margin  gross-profit-margin  cogs-margin  \\\n",
       "AACG_GURE           NaN             0.993198     0.993199   \n",
       "PEBO_UBOH           NaN             0.992070     0.992069   \n",
       "CVBF_FCCO           NaN             0.990282     0.990282   \n",
       "FBIZ_UBOH           NaN             0.987049     0.987048   \n",
       "AUB_HAFC            NaN             0.986588     0.986588   \n",
       "\n",
       "           eps-earnings-per-share-diluted  all-fundamental-variables  \\\n",
       "AACG_GURE                        0.586029                  -0.586037   \n",
       "PEBO_UBOH                        0.643873                   0.643874   \n",
       "CVBF_FCCO                       -0.557460                   0.557460   \n",
       "FBIZ_UBOH                        0.769316                   0.769318   \n",
       "AUB_HAFC                        -0.661878                   0.661878   \n",
       "\n",
       "           price-pairs  \n",
       "AACG_GURE          NaN  \n",
       "PEBO_UBOH     0.901189  \n",
       "CVBF_FCCO          NaN  \n",
       "FBIZ_UBOH     0.768724  \n",
       "AUB_HAFC      0.795130  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Sum of Squared distance on a one by one basis\n",
    "\n",
    "# (1) Get the distance for the price\n",
    "price_pairs = get_distance(yearly_normalized_price)\n",
    "price_pairs.to_csv(\"csv/distance price.csv\")\n",
    "\n",
    "\n",
    "# (2) Get the distance for the other variables\n",
    "fundamental_variable_pairs = {}\n",
    "for variable in fundamental_scores:\n",
    "    fundamental_pairs = get_distance(fundamental_scores[variable])\n",
    "    fundamental_variable_pairs[variable] = fundamental_pairs\n",
    "    fundamental_pairs.to_csv(\"csv/distance {}.csv\".format(variable))\n",
    "\n",
    "\n",
    "# (3) Combine the distances\n",
    "price_pairs.name = 'price-pairs'\n",
    "pairs = pd.concat([fundamental_variable_pairs[col] for col in fundamental_variable_pairs], axis=1)\n",
    "pairs.columns = [col for col in fundamental_variable_pairs]\n",
    "pairs = pairs.merge(price_pairs, how='left', left_index=True, right_index=True)\n",
    "\n",
    "pairs.to_csv('csv/distance combined one variable method.csv')\n",
    "\n",
    "# (4) Here is how the results look like\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-01f6f412ffc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Please note that columns where all values are NaN are dropped before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# any calculation is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprice_pairs_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myearly_normalized_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfundamental_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfundamental_scores\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprice_pairs_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distance price & all variables.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_distance' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the Sum of Squared distance by first combining\n",
    "# information provided from each of the stocks. e.g multiplying\n",
    "# the value of the normalized value of a variable such as ebtda-margin\n",
    "# with another variable e.g cost-of-goods-sold margin and using \n",
    "# the new value to calculate the sum of squared distance\n",
    "\n",
    "# (1) Get the Sum of squared difference for combined everything\n",
    "# this is calculated by normalized value price * ebtda * cost-of-goods-sold ...\n",
    "# then calculating the sum of squared difference between each stock\n",
    "# Please note that columns where all values are NaN are dropped before\n",
    "# any calculation is done\n",
    "price_pairs_2 = get_distance(yearly_normalized_price, [fundamental_scores[variable] for variable in fundamental_scores])\n",
    "price_pairs_2.to_csv(\"csv/distance price & all variables.csv\")\n",
    "\n",
    "\n",
    "# (2) Get the distance for the other variables\n",
    "fundamental_variable_pairs = {}\n",
    "for variable in fundamental_scores:\n",
    "    fundamental_pairs = get_distance(yearly_normalized_price, [fundamental_scores[variable]])\n",
    "    fundamental_variable_pairs[variable] = fundamental_pairs\n",
    "    fundamental_pairs.to_csv(\"csv/distance {} and price.csv\".format(variable))\n",
    "\n",
    "\n",
    "# (3) Combine the distances\n",
    "price_pairs_2.name = 'price-pairs'\n",
    "pairs = pd.concat([fundamental_variable_pairs[col] for col in fundamental_variable_pairs], axis=1)\n",
    "pairs.columns = [\"distance {} and price\".format(col) for col in fundamental_variable_pairs]\n",
    "# pairs = pairs.merge(price_pairs_2, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# pairs.to_csv('csv/distance combined multiple variable method.csv')\n",
    "\n",
    "# (4) Here is how the results look like\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'distance all-fundamental-variables and price.csv'\n",
    "b = 'distance cogs-margin and price.csv'\n",
    "c = 'distance ebtda-margin and price.csv'\n",
    "d = 'distance eps-earnings-per-share-diluted and price.csv'\n",
    "e = 'distance gross-profit-margin and price.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# x = pd.concat([pd.read_csv(x) for x in [a, b, c, d]], axis=1)\n",
    "\n",
    "dfs = []\n",
    "for x in [a, b, c, d]:\n",
    "    df = pd.read_csv(x)\n",
    "    df.rename(columns= {'0': x.split(\" \")[1], 'Unnamed: 0': 'stock pair'}, inplace=True)\n",
    "    df = df.set_index('stock pair')\n",
    "    dfs.append(df)\n",
    "\n",
    "x = pd.concat(dfs, axis=1)\n",
    "x.to_csv('csv/distance combined multiple variable method.csv')\n",
    "x['all-fundamental-variables'] = abs(x['all-fundamental-variables'])\n",
    "\n",
    "y = x['all-fundamental-variables'].dropna()\n",
    "y = y.sort_values(ascending=False)\n",
    "\n",
    "top_ten_method_2 = y.head(10)\n",
    "bottom_ten_method_2 = y.tail(10)\n",
    "\n",
    "top_ten_method_2.to_csv('csv/top ten method 2.csv')\n",
    "bottom_ten_method_2.to_csv('csv/bottom ten method 2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "method1_df = pd.read_csv('distance combined one variable method.csv')\n",
    "method1_df = method1_df[(method1_df['price-pairs'] > 0) & (method1_df['all-fundamental-variables'] > 0)]\n",
    "method1_df['pairs'] = method1_df['price-pairs'] * method1_df['all-fundamental-variables']\n",
    "\n",
    "method1_df.rename(columns={'Unnamed: 0': 'stock pair'}, inplace=True)\n",
    "method1_df = method1_df.set_index('stock pair')\n",
    "\n",
    "method1_pairs = abs(method1_df['pairs'])\n",
    "method1_pairs.dropna(inplace=True)\n",
    "method1_pairs.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "top_ten_method_1 = method1_pairs.head(10)\n",
    "bottom_ten_method_1 = method1_pairs.tail(10)\n",
    "\n",
    "top_ten_method_1.to_csv('csv/top ten method 1.csv')\n",
    "bottom_ten_method_1.to_csv('csv/bottom ten method 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ebtda-margin</th>\n",
       "      <th>gross-profit-margin</th>\n",
       "      <th>cogs-margin</th>\n",
       "      <th>eps-earnings-per-share-diluted</th>\n",
       "      <th>all-fundamental-variables</th>\n",
       "      <th>price-pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACG_GURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993198</td>\n",
       "      <td>0.993199</td>\n",
       "      <td>0.586029</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEBO_UBOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992070</td>\n",
       "      <td>0.992069</td>\n",
       "      <td>0.643873</td>\n",
       "      <td>0.643874</td>\n",
       "      <td>0.901189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVBF_FCCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990282</td>\n",
       "      <td>0.990282</td>\n",
       "      <td>-0.557460</td>\n",
       "      <td>0.557460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBIZ_UBOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987049</td>\n",
       "      <td>0.987048</td>\n",
       "      <td>0.769316</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.768724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUB_HAFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986588</td>\n",
       "      <td>0.986588</td>\n",
       "      <td>-0.661878</td>\n",
       "      <td>0.661878</td>\n",
       "      <td>0.795130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  ebtda-margin  gross-profit-margin  cogs-margin  \\\n",
       "0  AACG_GURE           NaN             0.993198     0.993199   \n",
       "1  PEBO_UBOH           NaN             0.992070     0.992069   \n",
       "2  CVBF_FCCO           NaN             0.990282     0.990282   \n",
       "3  FBIZ_UBOH           NaN             0.987049     0.987048   \n",
       "4   AUB_HAFC           NaN             0.986588     0.986588   \n",
       "\n",
       "   eps-earnings-per-share-diluted  all-fundamental-variables  price-pairs  \n",
       "0                        0.586029                  -0.586037          NaN  \n",
       "1                        0.643873                   0.643874     0.901189  \n",
       "2                       -0.557460                   0.557460          NaN  \n",
       "3                        0.769316                   0.769318     0.768724  \n",
       "4                       -0.661878                   0.661878     0.795130  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"distance combined one variable method.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_csv(\"distance price.csv\")\n",
    "price.rename(columns={'Unnamed: 0': 'pair', '0': 'distance'}, inplace=True)\n",
    "price = price.set_index('pair')\n",
    "price['distance'] = abs(price['distance'])\n",
    "price['distance'] = price['distance'].sort_values()\n",
    "\n",
    "price['distance'] = price['distance'].sort_values(ascending=False)\n",
    "top_ten_traditional = price.head(10)\n",
    "top_ten_traditional.to_csv('csv/top ten price distance traditional.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pair\n",
       "GOOGL_INTU    0.990578\n",
       "AUB_ONB       0.990565\n",
       "CIVB_FCCO     0.984932\n",
       "CIVB_PFC      0.984857\n",
       "EFSC_FCCO     0.984058\n",
       "ESLT_LMAT     0.983733\n",
       "CIVB_EFSC     0.982317\n",
       "AROW_TRMK     0.982065\n",
       "CSWC_GOOGL    0.980652\n",
       "CCOI_SBUX     0.980311\n",
       "Name: distance, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_method_1\n",
    "top_ten_traditional = top_ten_traditional['distance']\n",
    "top_ten_method_2\n",
    "top_ten_traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIVB', 'CCOI', 'FCCO', 'IMKTA', 'AROW']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We get a list of stocks from the pairs calculated above\n",
    "\n",
    "def get_stocks(pair_list):\n",
    "    result = []\n",
    "    for pair in pair_list:\n",
    "        result.append(pair.split('_')[0])\n",
    "        result.append(pair.split('_')[1])\n",
    "\n",
    "    return list(set(result))\n",
    "\n",
    "pairs_method_1 = get_stocks(top_ten_method_1.keys())\n",
    "pairs_method_2 = get_stocks(top_ten_method_2.keys())\n",
    "pairs_traditional = get_stocks(top_ten_traditional.keys())\n",
    "all_stocks = list(set(pairs_method_1 + pairs_method_2 + pairs_method_3))\n",
    "all_stocks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_data = get_monthly_adjusted_price(all_stocks, start_year=2009)\n",
    "pairs_data.to_csv(\"csv/pairs data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>AUB_PFC</th>\n",
       "      <th>EBTC_FNLC</th>\n",
       "      <th>CBSH_PFC</th>\n",
       "      <th>GOOGL_NFLX</th>\n",
       "      <th>EXLS_IMKTA</th>\n",
       "      <th>AUB_CBSH</th>\n",
       "      <th>EBTC_HBNC</th>\n",
       "      <th>BRKL_PFC</th>\n",
       "      <th>FELE_NSIT</th>\n",
       "      <th>CBSH_FNLC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2009</th>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064330</td>\n",
       "      <td>1.260456</td>\n",
       "      <td>1.317906</td>\n",
       "      <td>0.995650</td>\n",
       "      <td>1.068565</td>\n",
       "      <td>0.807592</td>\n",
       "      <td>0.975746</td>\n",
       "      <td>1.240071</td>\n",
       "      <td>1.674649</td>\n",
       "      <td>1.358774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.008749</td>\n",
       "      <td>0.899864</td>\n",
       "      <td>1.183076</td>\n",
       "      <td>0.865736</td>\n",
       "      <td>1.035618</td>\n",
       "      <td>0.852649</td>\n",
       "      <td>0.992764</td>\n",
       "      <td>1.143146</td>\n",
       "      <td>1.447827</td>\n",
       "      <td>1.051652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719140</td>\n",
       "      <td>1.020789</td>\n",
       "      <td>0.623264</td>\n",
       "      <td>0.932952</td>\n",
       "      <td>1.058505</td>\n",
       "      <td>1.153828</td>\n",
       "      <td>0.902405</td>\n",
       "      <td>0.695490</td>\n",
       "      <td>0.829136</td>\n",
       "      <td>0.861681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.445195</td>\n",
       "      <td>1.159314</td>\n",
       "      <td>0.429971</td>\n",
       "      <td>1.129926</td>\n",
       "      <td>1.176064</td>\n",
       "      <td>1.035407</td>\n",
       "      <td>0.793943</td>\n",
       "      <td>0.502175</td>\n",
       "      <td>0.633683</td>\n",
       "      <td>0.842225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUB_PFC  EBTC_FNLC  CBSH_PFC  GOOGL_NFLX  EXLS_IMKTA  AUB_CBSH  \\\n",
       "year month                                                                    \n",
       "2009 1      1.000000   1.000000  1.000000    1.000000    1.000000  1.000000   \n",
       "     2      1.064330   1.260456  1.317906    0.995650    1.068565  0.807592   \n",
       "     3      1.008749   0.899864  1.183076    0.865736    1.035618  0.852649   \n",
       "     4      0.719140   1.020789  0.623264    0.932952    1.058505  1.153828   \n",
       "     5      0.445195   1.159314  0.429971    1.129926    1.176064  1.035407   \n",
       "\n",
       "            EBTC_HBNC  BRKL_PFC  FELE_NSIT  CBSH_FNLC  \n",
       "year month                                             \n",
       "2009 1       1.000000  1.000000   1.000000   1.000000  \n",
       "     2       0.975746  1.240071   1.674649   1.358774  \n",
       "     3       0.992764  1.143146   1.447827   1.051652  \n",
       "     4       0.902405  0.695490   0.829136   0.861681  \n",
       "     5       0.793943  0.502175   0.633683   0.842225  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the relative prices\n",
    "\n",
    "def get_relative_price(pairs, pairs_data):\n",
    "    stock_pairs_arr = []\n",
    "    for pair in pairs.keys():\n",
    "        stock1 = pair.split(\"_\")[0]\n",
    "        stock2 = pair.split(\"_\")[1]\n",
    "\n",
    "        relative_price = pairs_data[stock1]/pairs_data[stock2]\n",
    "        relative_price.name = pair\n",
    "        stock_pairs_arr.append(relative_price)\n",
    "\n",
    "    return pd.concat(stock_pairs_arr, axis=1)\n",
    "\n",
    "relative_prices_method_1 = get_relative_price(top_ten_method_1, pairs_data)\n",
    "relative_prices_method_2 = get_relative_price(top_ten_method_2, pairs_data)\n",
    "relative_prices_traditional = get_relative_price(top_ten_traditional, pairs_data)\n",
    "\n",
    "relative_prices_method_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data summary\n",
    "\n",
    "def filter_data(df, min_year=2009, min_month=1, max_year=2023, max_month=12):\n",
    "    period_df = df[(df.index >= (min_year, min_month)) & (df.index < (max_year, max_month))]\n",
    "\n",
    "    return period_df\n",
    "\n",
    "def get_summary(df, min_year=2009, min_month=1, max_year=2016, max_month=12):\n",
    "    data = filter_data(df, min_year, min_month, max_year, max_month)\n",
    "    return data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUB_PFC</th>\n",
       "      <th>EBTC_FNLC</th>\n",
       "      <th>CBSH_PFC</th>\n",
       "      <th>GOOGL_NFLX</th>\n",
       "      <th>EXLS_IMKTA</th>\n",
       "      <th>AUB_CBSH</th>\n",
       "      <th>EBTC_HBNC</th>\n",
       "      <th>BRKL_PFC</th>\n",
       "      <th>FELE_NSIT</th>\n",
       "      <th>CBSH_FNLC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.423316</td>\n",
       "      <td>1.552284</td>\n",
       "      <td>0.507285</td>\n",
       "      <td>0.511655</td>\n",
       "      <td>1.755958</td>\n",
       "      <td>0.861938</td>\n",
       "      <td>0.613368</td>\n",
       "      <td>0.421809</td>\n",
       "      <td>0.620538</td>\n",
       "      <td>1.170059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.141772</td>\n",
       "      <td>0.249681</td>\n",
       "      <td>0.192622</td>\n",
       "      <td>0.338735</td>\n",
       "      <td>0.486212</td>\n",
       "      <td>0.138005</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>0.207335</td>\n",
       "      <td>0.183860</td>\n",
       "      <td>0.129057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.272472</td>\n",
       "      <td>0.899864</td>\n",
       "      <td>0.291560</td>\n",
       "      <td>0.171606</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.585047</td>\n",
       "      <td>0.441800</td>\n",
       "      <td>0.219627</td>\n",
       "      <td>0.410453</td>\n",
       "      <td>0.748376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.342319</td>\n",
       "      <td>1.392368</td>\n",
       "      <td>0.358948</td>\n",
       "      <td>0.252650</td>\n",
       "      <td>1.413532</td>\n",
       "      <td>0.743339</td>\n",
       "      <td>0.505924</td>\n",
       "      <td>0.258588</td>\n",
       "      <td>0.501459</td>\n",
       "      <td>1.079076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.401689</td>\n",
       "      <td>1.580602</td>\n",
       "      <td>0.447511</td>\n",
       "      <td>0.341169</td>\n",
       "      <td>1.728181</td>\n",
       "      <td>0.897475</td>\n",
       "      <td>0.534997</td>\n",
       "      <td>0.350221</td>\n",
       "      <td>0.565591</td>\n",
       "      <td>1.201857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.439547</td>\n",
       "      <td>1.723493</td>\n",
       "      <td>0.601757</td>\n",
       "      <td>0.818321</td>\n",
       "      <td>2.136278</td>\n",
       "      <td>0.959208</td>\n",
       "      <td>0.700425</td>\n",
       "      <td>0.509509</td>\n",
       "      <td>0.696389</td>\n",
       "      <td>1.258840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.064330</td>\n",
       "      <td>2.056830</td>\n",
       "      <td>1.317906</td>\n",
       "      <td>1.479558</td>\n",
       "      <td>2.779984</td>\n",
       "      <td>1.153828</td>\n",
       "      <td>1.112004</td>\n",
       "      <td>1.240071</td>\n",
       "      <td>1.674649</td>\n",
       "      <td>1.389974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUB_PFC  EBTC_FNLC   CBSH_PFC  GOOGL_NFLX  EXLS_IMKTA   AUB_CBSH  \\\n",
       "count  95.000000  95.000000  95.000000   95.000000   95.000000  95.000000   \n",
       "mean    0.423316   1.552284   0.507285    0.511655    1.755958   0.861938   \n",
       "std     0.141772   0.249681   0.192622    0.338735    0.486212   0.138005   \n",
       "min     0.272472   0.899864   0.291560    0.171606    0.950682   0.585047   \n",
       "25%     0.342319   1.392368   0.358948    0.252650    1.413532   0.743339   \n",
       "50%     0.401689   1.580602   0.447511    0.341169    1.728181   0.897475   \n",
       "75%     0.439547   1.723493   0.601757    0.818321    2.136278   0.959208   \n",
       "max     1.064330   2.056830   1.317906    1.479558    2.779984   1.153828   \n",
       "\n",
       "       EBTC_HBNC   BRKL_PFC  FELE_NSIT  CBSH_FNLC  \n",
       "count  95.000000  95.000000  95.000000  95.000000  \n",
       "mean    0.613368   0.421809   0.620538   1.170059  \n",
       "std     0.156768   0.207335   0.183860   0.129057  \n",
       "min     0.441800   0.219627   0.410453   0.748376  \n",
       "25%     0.505924   0.258588   0.501459   1.079076  \n",
       "50%     0.534997   0.350221   0.565591   1.201857  \n",
       "75%     0.700425   0.509509   0.696389   1.258840  \n",
       "max     1.112004   1.240071   1.674649   1.389974  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_method_1 = get_summary(relative_prices_method_1)\n",
    "summary_method_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time for opening and closing the long-short position in the\n",
    "# stock pair\n",
    "def get_entry_and_exit_points(relative_prices, mean, std):\n",
    "    result = []\n",
    "    next_position = 'open'\n",
    "    trade = {}\n",
    "    for rp, date in zip(relative_prices, relative_prices.index):\n",
    "        big = rp > mean + (2 * std)\n",
    "        small = rp < mean - (2 * std)\n",
    "        if (big or small) and (next_position == 'open'):\n",
    "            trade['start'] = date\n",
    "            next_position = 'close'\n",
    "        elif (abs(rp) < abs(mean + (2 * std))) and (next_position == 'close'):\n",
    "            trade['end'] = date\n",
    "            result.append(trade)\n",
    "\n",
    "            next_position = 'open'\n",
    "            trade = {}\n",
    "\n",
    "    return result\n",
    "\n",
    "# Get the relative prices, mean, and standard deviation of the stocks\n",
    "def get_pair_info(pair, relative_prices):\n",
    "    pair_summary = get_summary(relative_prices)\n",
    "    relative_price = filter_data(relative_prices, min_year=2017)[pair]\n",
    "    std = pair_summary.loc['std', pair]\n",
    "    mean = pair_summary.loc['mean', pair]\n",
    "\n",
    "    return {\"relative price\": relative_price, \"mean\": mean, \"std\": std}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the trades that we should make for each of the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades(relative_prices):\n",
    "    result = {}\n",
    "    for pair in relative_prices.columns:\n",
    "        \n",
    "        pair_info = get_pair_info(pair, relative_prices)\n",
    "        rp = pair_info['relative price']\n",
    "        mean = pair_info['mean']\n",
    "        std = pair_info['std']\n",
    "\n",
    "        entry_and_exit = get_entry_and_exit_points(rp, mean, std)\n",
    "\n",
    "        result[pair] = entry_and_exit\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_trade_count(trades):\n",
    "    no_of_trades = {}\n",
    "    for pair in trades:\n",
    "        no_of_trades[pair] = len(trades[pair])\n",
    "\n",
    "    return pd.Series(no_of_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUB_PFC': [],\n",
       " 'EBTC_FNLC': [],\n",
       " 'CBSH_PFC': [],\n",
       " 'GOOGL_NFLX': [],\n",
       " 'EXLS_IMKTA': [{'start': (2017, 8), 'end': (2017, 12)},\n",
       "  {'start': (2019, 3), 'end': (2019, 5)},\n",
       "  {'start': (2019, 7), 'end': (2019, 8)},\n",
       "  {'start': (2020, 11), 'end': (2020, 12)}],\n",
       " 'AUB_CBSH': [{'start': (2017, 11), 'end': (2017, 12)}],\n",
       " 'EBTC_HBNC': [],\n",
       " 'BRKL_PFC': [],\n",
       " 'FELE_NSIT': [],\n",
       " 'CBSH_FNLC': [{'start': (2017, 10), 'end': (2017, 11)},\n",
       "  {'start': (2020, 5), 'end': (2020, 6)}]}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_1_trades = get_trades(relative_prices_method_1)\n",
    "method_1_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUB_PFC       0\n",
       "EBTC_FNLC     0\n",
       "CBSH_PFC      0\n",
       "GOOGL_NFLX    0\n",
       "EXLS_IMKTA    4\n",
       "AUB_CBSH      1\n",
       "EBTC_HBNC     0\n",
       "BRKL_PFC      0\n",
       "FELE_NSIT     0\n",
       "CBSH_FNLC     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trade_count(method_1_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHI_CSWC     2\n",
       "CGO_CHI      9\n",
       "CGO_HSKA     0\n",
       "CPSS_ECPG    1\n",
       "CHI_HSKA     0\n",
       "CSWC_HSKA    0\n",
       "CGO_CSWC     4\n",
       "ARWR_CGO     1\n",
       "CSWC_DHIL    0\n",
       "ARWR_CHI     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_2_trades = get_trades(relative_prices_method_2)\n",
    "get_trade_count(method_2_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GOOGL_INTU': [{'start': (2019, 2), 'end': (2019, 3)},\n",
       "  {'start': (2019, 5), 'end': (2019, 6)},\n",
       "  {'start': (2019, 7), 'end': (2019, 8)},\n",
       "  {'start': (2019, 9), 'end': (2019, 10)},\n",
       "  {'start': (2020, 8), 'end': (2020, 9)},\n",
       "  {'start': (2020, 12), 'end': (2021, 1)},\n",
       "  {'start': (2021, 10), 'end': (2021, 11)},\n",
       "  {'start': (2021, 12), 'end': (2022, 1)},\n",
       "  {'start': (2022, 10), 'end': (2022, 11)},\n",
       "  {'start': (2022, 12), 'end': (2023, 1)},\n",
       "  {'start': (2023, 2), 'end': (2023, 3)},\n",
       "  {'start': (2023, 4), 'end': (2023, 5)}],\n",
       " 'AUB_ONB': [{'start': (2017, 5), 'end': (2017, 6)},\n",
       "  {'start': (2018, 1), 'end': (2018, 6)},\n",
       "  {'start': (2019, 4), 'end': (2019, 5)},\n",
       "  {'start': (2019, 6), 'end': (2019, 10)},\n",
       "  {'start': (2021, 5), 'end': (2021, 6)},\n",
       "  {'start': (2021, 7), 'end': (2021, 10)},\n",
       "  {'start': (2022, 1), 'end': (2022, 7)},\n",
       "  {'start': (2023, 1), 'end': (2023, 5)}],\n",
       " 'CIVB_FCCO': [{'start': (2017, 9), 'end': (2017, 10)},\n",
       "  {'start': (2019, 3), 'end': (2019, 11)},\n",
       "  {'start': (2019, 12), 'end': (2020, 1)},\n",
       "  {'start': (2021, 3), 'end': (2021, 6)},\n",
       "  {'start': (2021, 7), 'end': (2022, 4)},\n",
       "  {'start': (2022, 5), 'end': (2022, 12)}],\n",
       " 'CIVB_PFC': [],\n",
       " 'EFSC_FCCO': [{'start': (2021, 3), 'end': (2021, 5)},\n",
       "  {'start': (2022, 7), 'end': (2022, 12)},\n",
       "  {'start': (2023, 1), 'end': (2023, 3)}],\n",
       " 'ESLT_LMAT': [],\n",
       " 'CIVB_EFSC': [],\n",
       " 'AROW_TRMK': [{'start': (2020, 2), 'end': (2020, 4)},\n",
       "  {'start': (2020, 5), 'end': (2020, 12)},\n",
       "  {'start': (2021, 6), 'end': (2021, 9)},\n",
       "  {'start': (2022, 5), 'end': (2022, 6)},\n",
       "  {'start': (2023, 1), 'end': (2023, 2)}],\n",
       " 'CSWC_GOOGL': [{'start': (2018, 1), 'end': (2018, 2)},\n",
       "  {'start': (2020, 3), 'end': (2020, 4)},\n",
       "  {'start': (2020, 5), 'end': (2020, 6)},\n",
       "  {'start': (2020, 7), 'end': (2020, 8)},\n",
       "  {'start': (2020, 9), 'end': (2020, 10)},\n",
       "  {'start': (2020, 11), 'end': (2020, 12)},\n",
       "  {'start': (2021, 1), 'end': (2021, 2)},\n",
       "  {'start': (2021, 6), 'end': (2021, 7)},\n",
       "  {'start': (2021, 8), 'end': (2021, 9)},\n",
       "  {'start': (2021, 12), 'end': (2022, 1)},\n",
       "  {'start': (2022, 2), 'end': (2022, 3)},\n",
       "  {'start': (2022, 6), 'end': (2022, 7)},\n",
       "  {'start': (2023, 5), 'end': (2023, 6)}],\n",
       " 'CCOI_SBUX': [{'start': (2018, 6), 'end': (2018, 7)},\n",
       "  {'start': (2020, 3), 'end': (2020, 5)},\n",
       "  {'start': (2020, 6), 'end': (2020, 8)}]}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traditional_trades = get_trades(relative_prices_traditional)\n",
    "traditional_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOOGL_INTU    12\n",
       "AUB_ONB        8\n",
       "CIVB_FCCO      6\n",
       "CIVB_PFC       0\n",
       "EFSC_FCCO      3\n",
       "ESLT_LMAT      0\n",
       "CIVB_EFSC      0\n",
       "AROW_TRMK      5\n",
       "CSWC_GOOGL    13\n",
       "CCOI_SBUX      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trade_count(traditional_trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Average Mean Reversion Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_difference(start, end):\n",
    "    '''\n",
    "    Receives two tuples in the form (2009, 1), (2010, 3) and returns the\n",
    "    difference between the two in number of months. The first vlaue is\n",
    "    expected to be the smaller one\n",
    "    '''\n",
    "    year_difference = end[0] - start[0]\n",
    "\n",
    "    return (year_difference * 12) + end[1] - start[1]\n",
    "\n",
    "def get_convertence_time(pair_trades):\n",
    "    \n",
    "    trades = []\n",
    "    for pair in pair_trades:\n",
    "        trades += pair_trades[pair]\n",
    "\n",
    "    trade_period = []\n",
    "    for trade in trades:\n",
    "        end = trade['end']\n",
    "        start = trade['start']\n",
    "\n",
    "        trade_period.append(get_month_difference(start, end))\n",
    "\n",
    "    return trade_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.14"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_period_traditional = get_convertence_time(traditional_trades)\n",
    "pd.Series(trade_period_traditional).to_csv('csv/trade period traditional.csv')\n",
    "average_convergence_time_traditional = sum(trade_period_traditional)/len(trade_period_traditional)\n",
    "average_convergence_time_traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5714285714285714"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_period_method_1 = get_convertence_time(method_1_trades)\n",
    "pd.Series(trade_period_method_1).to_csv('csv/trade period method 1.csv')\n",
    "average_convergence_time_traditional = sum(trade_period_method_1)/len(trade_period_method_1)\n",
    "average_convergence_time_traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.190476190476191"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_period_method_2 = get_convertence_time(method_2_trades)\n",
    "pd.Series(trade_period_method_2).to_csv('csv/trade period method 2.csv')\n",
    "average_convergence_time_traditional = sum(trade_period_method_2)/len(trade_period_method_2)\n",
    "average_convergence_time_traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(pair, price_df, trade_info):\n",
    "    stock1 = pair.split('_')[0]\n",
    "    stock2 = pair.split('_')[1]\n",
    "\n",
    "    trades = trade_info[pair]\n",
    "\n",
    "    result = []\n",
    "    for trade in trades:\n",
    "        stock1_start_price = price_df.loc[trade['start'], stock1]\n",
    "        stock1_end_price = price_df.loc[trade['end'], stock1]\n",
    "        stock2_start_price = price_df.loc[trade['start'], stock2]\n",
    "        stock2_end_price = price_df.loc[trade['end'], stock2]\n",
    "\n",
    "        stock1_difference = abs(stock1_end_price - stock1_start_price)/stock1_start_price\n",
    "        stock2_difference = abs(stock2_end_price - stock2_start_price)/stock2_start_price\n",
    "\n",
    "        return_val = abs(stock1_difference - stock2_difference)\n",
    "        month_count = get_month_difference(trade['start'], trade['end'])\n",
    "\n",
    "        result.append(return_val / month_count)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03472318219111427"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traditional_profits = []\n",
    "\n",
    "for pair in relative_prices_traditional:\n",
    "    traditional_profits += get_profit(pair, pairs_data, traditional_trades)\n",
    "\n",
    "sum(traditional_profits)/len(traditional_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07839440576439947"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_1_profits = []\n",
    "\n",
    "for pair in relative_prices_method_1:\n",
    "    method_1_profits += get_profit(pair, pairs_data, method_1_trades)\n",
    "\n",
    "sum(method_1_profits)/len(method_1_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03572954047576432"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_2_profits = []\n",
    "\n",
    "for pair in relative_prices_method_2:\n",
    "    method_2_profits += get_profit(pair, pairs_data, method_2_trades)\n",
    "\n",
    "sum(method_2_profits)/len(method_2_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Series(traditional_profits)\n",
    "t.name = 'traditional'\n",
    "t.to_csv('csv/traditional profits.csv')\n",
    "m1 = pd.Series(method_1_profits)\n",
    "m1.name = 'method 1'\n",
    "m1.to_csv('csv/method 1 profits.csv')\n",
    "m2 = pd.Series(method_2_profits)\n",
    "m2.name = 'method 2'\n",
    "m2.to_csv('csv/method 2 profits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ee0ec614d0abf57fdc8a4c4d1b373279e4d39776338528fabf72ad422f0613a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
